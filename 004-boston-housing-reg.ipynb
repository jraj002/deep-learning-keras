{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers\n",
    "from keras import optimizers\n",
    "from keras import losses, metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the Boston housing dataset\n",
    "from keras.datasets import boston_housing\n",
    "(train_data, train_targets), (test_data, test_targets) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n",
      "------------------------------------------------------------\n",
      "[  1.23247   0.        8.14      0.        0.538     6.142    91.7\n",
      "   3.9769    4.      307.       21.      396.9      18.72   ]\n",
      "------------------------------------------------------------\n",
      "[15.2 42.3 50.  21.1 17.7 18.5 11.3 15.6 15.6 14.4]\n"
     ]
    }
   ],
   "source": [
    "## peek at train data shape\n",
    "print(train_data.shape)\n",
    "print(\"---\"*20)\n",
    "print(train_data[0])\n",
    "print(\"---\"*20)\n",
    "print(train_targets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 13)\n",
      "------------------------------------------------------------\n",
      "[ 18.0846   0.      18.1      0.       0.679    6.434  100.       1.8347\n",
      "  24.     666.      20.2     27.25    29.05  ]\n",
      "------------------------------------------------------------\n",
      "[ 7.2 18.8 19.  27.  22.2 24.5 31.2 22.9 20.5 23.2]\n"
     ]
    }
   ],
   "source": [
    "## peek at test data shape\n",
    "print(test_data.shape)\n",
    "print(\"---\"*20)\n",
    "print(test_data[0])\n",
    "print(\"---\"*20)\n",
    "print(test_targets[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## normalize the data\n",
    "## calculate mean for all columns\n",
    "mean = train_data.mean(axis=0)\n",
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.74511057e+00, 1.14801980e+01, 1.11044307e+01, 6.18811881e-02,\n",
       "       5.57355941e-01, 6.26708168e+00, 6.90106436e+01, 3.74027079e+00,\n",
       "       9.44059406e+00, 4.05898515e+02, 1.84759901e+01, 3.54783168e+02,\n",
       "       1.27408168e+01])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## subtract mean of each column from the data point\n",
    "train_data = train_data - mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate standard deviation along each column and subtract from data point\n",
    "std = train_data.std(axis=0)\n",
    "train_data = train_data/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalize the test data using the previously calculated mean/std\n",
    "test_data = test_data - mean\n",
    "test_data = test_data/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## build model\n",
    "def build_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(64, activation='relu', input_shape=(train_data.shape[1],)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    model.compile(optimizer=optimizers.RMSprop(lr=0.001), loss=losses.mse, metrics=[metrics.mae])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## k-fold validation\n",
    "import numpy as np\n",
    "\n",
    "k=4\n",
    "num_val_samples = len(train_data) // k\n",
    "num_epochs = 100\n",
    "all_scores = []\n",
    "\n",
    "for i in range(k):\n",
    "    print ('processing fold #', i)\n",
    "    val_data = train_data[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    val_targets = train_targets[i * num_val_samples: (i+1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate(\n",
    "    [train_data[:i*num_val_samples], \n",
    "    train_data[(i+1)*num_val_samples:]],\n",
    "    axis=0)\n",
    "    \n",
    "    partial_train_targets = np.concatenate(\n",
    "    [train_targets[:i*num_val_samples], \n",
    "    train_targets[(i+1)*num_val_samples:]],\n",
    "    axis=0)\n",
    "    \n",
    "    model = build_model()\n",
    "    model.fit(partial_train_data, partial_train_targets, epochs=num_epochs, batch_size=1)\n",
    "    \n",
    "    val_mse, val_mae = model.evaluate(val_data, val_targets, verbose=0)\n",
    "    all_scores.append(val_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0581326413862775, 2.2001309324019025, 2.8750618802438868, 2.410775157484678]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.386025152879186"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
